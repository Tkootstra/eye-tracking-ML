# -*- coding: utf-8 -*-
"""
Created on Mon Oct 22 14:07:29 2018

@author: timok

Warning: this script will take a long time to run. if preferred, you can download the results directly.

"""


import pandas as pd
import numpy as np
import warnings
from sklearn.preprocessing import LabelBinarizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.exceptions import DataConversionWarning
warnings.filterwarnings(action='ignore', category=DataConversionWarning)


dataframe_kFold_split = pd.read_csv('CV_split.csv')
dataframe_kFold_split = dataframe_kFold_split.reset_index()

input_features = [x for x in dataframe_kFold_split.columns if 'fix' in x or 'sacc' in x]
output_feature = 'trialtype'



def makeCViterable(dataframe): # make iterable of splits for sklearn CV implementation
    CV_iterator = []
    for x in range(1,dataframe['cat'].nunique() +1):
        trainIndices = dataframe[dataframe['cat'] != x].index.values.astype(int)
        validationIndices = dataframe[dataframe['cat'] == x].index.values.astype(int)
        CV_iterator.append((trainIndices, validationIndices))
    return CV_iterator


        
CV_iterator = makeCViterable(dataframe_kFold_split)


estimator = RandomForestClassifier(n_estimators=800, n_jobs = -1)
from skopt.space import Real, Integer, Categorical
from skopt.utils import use_named_args
from sklearn.model_selection import cross_val_score


X = dataframe_kFold_split[input_features]

y = dataframe_kFold_split[output_feature]
binarizer = LabelBinarizer()
y = binarizer.fit_transform(y)

space = [Integer(1, 100, name='min_samples_leaf'),
         Integer(1, len(input_features), name='max_features'),
         Integer(2, 100, name='min_samples_split'),
         Integer(2, 100, name='max_depth'),
         Categorical(['gini', 'entropy'], name = 'criterion')]
    

    
@use_named_args(space)
def objective(**params):
    estimator.set_params(**params)
    
    return -np.mean(cross_val_score(estimator,X,y, cv=CV_iterator, n_jobs=-1, scoring='roc_auc'))



from skopt import gp_minimize


estimator_gaussian_process = gp_minimize(objective, space, n_calls=35, verbose=True)

print("Best score=%.4f" % estimator_gaussian_process.fun)


best_params = list(estimator_gaussian_process.x)

best_model = RandomForestClassifier(n_estimators=800, min_samples_leaf=best_params[0], max_features=best_params[1],
                                    min_samples_split=best_params[2], max_depth=best_params[3], 
                                    criterion=best_params[4]
                                                                 
                                    )

print(best_model)
from skopt import dump

dump(estimator_gaussian_process, 'RF_Bayesian_results.pkl')

from skopt.plots import plot_convergence
plot_convergence(estimator_gaussian_process)      



from skopt import load


test = load('RF_Bayesian_results.pkl')















































    

